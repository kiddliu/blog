[浮点数的比较，2012版](https://randomascii.wordpress.com/2012/02/25/comparing-floating-point-numbers-2012-edition/)
==

很多年前我写过一篇关于浮点数比较的文章，而这一篇更是经过了深思熟虑，也经过了同行评审，针对浮点数这个复杂的问题给出了扎实的建议和一些令人惊讶的发现。

我们也终于谈到了这个博客系列里我最期待的地方。在这篇文章中我准备分享我的浮点数学知识中最关键的点。那就是：

[浮点]数学太难了。

你完全不会相信它是这样的难。我是说也许你会觉得计算从芝加哥到洛杉矶的火车什么时候翻车比较难，但是跟浮点数学相比那简直是小菜一碟。

我是认真的。每一次当我认为自己掌握了浮点数学中各种细微之处和含义的时候，我都发现我错了——还是有一些令人感到困惑的因素没有考虑到。所以，值得铭记的教训就是浮点数学总是比你想象的更加复杂。希望你在阅读文章剩余部分的时候谨记这一点，并且理解——文章中确实给了一些技巧上的建议，但是它们并不总是有效的。

前情概要
--

这是系列中的第五篇文章。系列的前几篇对于理解这一篇文章非常重要。完整的文章列表如下：

相等的比较
--

浮点数学并不精确。类似0.1这样简单的数并不能用二进制浮点数准确的表示，而浮点数有限的精度意味着诸如运算顺序的细微变化或者中间运算结果的精度都可以影响到结果。这意味着，比较两个浮点数从而判断它们是否相等通常并不是你想要的。GCC甚至对这样的操作给出了警告：“警告：用`==`或者`!=`比较浮点数是不安全的”。

一个体现这种不精确的例子如下：
```cpp
float f = 0.1f;
float sum;
sum = 0;

for (int i = 0; i < 10; ++i)
    sum += f;
float product = f * 10;
printf("sum = %1.15f, mul = %1.15f, mul2 = %1.15f\n",
        sum, product, f * 10);
```
这段代码尝试用三种不同的方式计算数值‘一’：重复的调用加法，和两种稍有不同的乘法。很自然地，我们得到了三个不同的结果，这其中只有一个是1.0：

_sum=1.000000119209290, mul=1.000000000000000, mul2=1.000000014901161_

在这里声明：你获得的结果受你的编译器和编译器设置的影响，实际上这个行为也在帮助我们理解这个问题。

那么，到底发生了什么？哪一个运算结果是正确的？

你所说的“正确”指的是什么？
--

在我们继续这个话题之前，让我们先厘清`0.1`，`float(0.1)`与`double(0.1)`之间的区别。在C/C++中`0.1`与`double(0.1)`是同一个东西，但是在文章里提到0.1的时候我是指那个十进制数字，而`float(0.1)`与`double(0.1)`是去除了尾数的0.1。再澄清一点，`float(0.1)`与`double(0.1)`并没有一样的值，因为`float(0.1)`的二进制表达中数字个数更少，也因此有更大的误差。下边列出了三者的精确数值：

| Number        | Value                                                     |
| ------------- |:----------------------------------------------------------|
| `0.1`           | 0.1                                                       |
| `float(0.1)`  | 0.100000001490116119384765625                             |
| `double(0.1)` | 0.1000000000000000055511151231257827021181583404541015625 |

搞清楚了这些，让我们回过头来看之前代码的输出结果：
1. `sum = 1.000000119209290`：这个计算方法的输入是一个去除了尾数的数值，然后执行了10次加法。其间的每一次加法都有可能去除了尾数，所以有很大的可能产生误差。最终结果不是1.0，也不是`10 * float(0.1)`。然而这个结果是大于1.0的下一个可表示浮点数，所以已经很接近了。
2. `mul = 1.000000000000000`：这个计算方法的输入也是一个去除了尾数的数值，然后执行了一次乘以10，所以没有什么机会引入误差。看起来，从`0.1`到`float(0.1)`的转换向上去除尾数了，但是乘以10碰巧向下去除了尾数，有的时候两次去尾数刚好得到了正确的结果。我们因为错误的原因得到了正确的结果。亦或者这是一个错误的答案，因为它并不是10倍的`float(0.1)`。
3. `mul2 = 1.000000014901161`：这个计算方法的输入也是一个去除了尾数的数值，然后执行了一次双精度乘法，因而避免了之后任何去除尾数的误差。因此我们获得了一个_不一样_的正确答案——精确的`10 * float(0.1)`（结果只能存储在一个双精度浮点数中，而不是一个单精度浮点数中）

总结一下，答案一是错的，但是与正确答案之间只有一个浮点值的差。答案二是正确的（但是并不精确），而答案三是完全正确的（但是看起来是错的）。

接下来呢？
--

现在我们有一些不一样的答案了（我准备直接忽略双精度的答案），那接下来呢？我们是寻找那个等于一的答案，但是如果我们也想把那些足够接近的答案也算进去呢？

精度比较
--

如果比较两个浮点数是否相等是个糟糕的想法，那么检查它们的差是否在某个误差范围或是精度范围之内怎么样？就像这样：

_bool isEqual = fabs(f1 – f2) <= epsilon;_

通过这样的计算我们表达了一个概念，当两个浮点数靠的足够近的时候我们愿意把它们当作相等的。但是我们应该选择什么样的值作为精度呢？

有了上面我们的实验结果，一个很自然的想法就是用这个和里的误差，大概是1.19e<sup>-7</sup>f。事实上在float.h头文件里就有定义这个值，叫做`FLT_EPSILON`。

如此清晰！老天爷发话了，`FLT_EPSILON`就是那个唯一精度值！

然并卵。对于在1.0和2.0之间的数值`FLT_EPSILON`代表着相邻浮点数值差。对于小于1.0的数值来说`FLT_EPSILON`很快就变的太大了，以至于对于足够小的数值来说`FLT_EPSILON`甚至比两个参与比较的数值还要大！

对于大于2.0的数值来说浮点数值之间的差在变大，如果再用`FLT_EPSILON`来比较浮点数的话事倍功半。即如果两个大于2.0的浮点数不相等的话那么它们之间的差一定大于`FLT_EPSILON`。对于大于16777216的数值来说合适的精度实际上已经大于一了，继续使用`FLT_EPSILON`就显得很傻了。我们可不傻。

相对精度比较
--

相对精度比较的想法是得到两个数字的差，然后和数字本身大小做比较。为了得到稳定的结果我们应该总是用差与两个数字中较大的那个数字去比较。用自然语言描述就是：

_为了比较f1与f2，计算diff = fabs(f1 - f2)。如果diff小于n个百分比的max(abs(f1), abs(f2))那么我们称f1与f2相等。_

用代码实现那就是：
```cpp
bool AlmostEqualRelative(float A, float B,
                         float maxRelDiff = FLT_EPSILON)
{
    // Calculate the difference.
    float diff = fabs(A - B);
    A = fabs(A);
    B = fabs(B);
    // Find the largest
    float largest = (B > A) ? B : A;

    if (diff <= largest * maxRelDiff)
        return true;
    return false;
}
```

这个函数还不错。至少大部分时间它工作正常。稍后我会提到它的一些局限性，但首先我想契合这篇文章的核心点——多年前我给出的建议性的技巧。

那就是在做相对精度比较的时候，把`maxRelDiff`设置为`FLT_EPSILON`，或者`FLT_EPSILON`很小的某个倍数。再比它们还小的话就要冒着等价于没有精度值的风险。你当然也可以把它定义的更大一些，如果更大的误差是可以容忍的，但是别大的太过份了。然而为`maxRelDiff`选择一个正确的值需要花精力调整，努力的方向也不明显，而与浮点数格式之间缺乏直接的关联也让我很难过。

ULP
--

我们已经知道相邻的两个浮点数有着相邻的整数表现形式。这意味着如果我们对两个浮点数整数形式相减那么差就告诉我们在浮点空间中两个数字相隔有多远。这给我们带来了：

Dawson的事后诸葛亮原理：

_如果两个同符号浮点数的整数表现形式相减，那么结果的绝对值等于两数之间的浮点数个数再加1。_

也就是说如果两个浮点数相减的结果是一，那么两个数足够接近但是不相等。如果结果是二，那么它们仍然很近，只有一个浮点数在它们之间。那么两个整数形式的差告诉我们它们之间有多少个最小精度差（Units in the Last Place）。通常缩写做ULP，比如“这两个浮点数相差两个ULP”。

让我们尝试一下这个概念：
```cpp
/* See
https://randomascii.wordpress.com/2012/01/11/tricks-with-the-floating-point-format/
for the potential portability problems with the union and bit-fields below.
*/
#include <stdint.h> // For int32_t, etc.

union Float_t
{
    Float_t(float num = 0.0f) : f(num) {}
    // Portable extraction of components.
    bool Negative() const { return i < 0; }
    int32_t RawMantissa() const { return i & ((1 << 23) - 1); }
    int32_t RawExponent() const { return (i >> 23) & 0xFF; }

    int32_t i;
    float f;
#ifdef _DEBUG
    struct
    {   // Bitfields for exploration. Do not use in production code.
        uint32_t mantissa : 23;
        uint32_t exponent : 8;
        uint32_t sign : 1;
    } parts;
#endif
};

bool AlmostEqualUlps(float A, float B, int maxUlpsDiff)
{
    Float_t uA(A);
    Float_t uB(B);

    // Different signs means they do not match.
    if (uA.Negative() != uB.Negative())
    {
        // Check for equality to make sure +0==-0
        if (A == B)
            return true;
        return false;
    }

    // Find the difference in ULPs.
    int ulpsDiff = abs(uA.i - uB.i);
    if (ulpsDiff <= maxUlpsDiff)
        return true;

    return false;
}
```

有意思，也很深奥。

有几个原因导致我们必须检查符号。用二进制补码处理两个有符号数相减并不是特别的有意义，而且相减有可能得到一个33位的结果导致溢出。即使我们处理了这样的情况，这也不会使基于ULP的浮点数比较变得有意义。

_即使一个非常小的数，比如1e<sup>-30</sup>的整数表现形式也有一个非常大的整数部分228737632。所以虽然1e<sup>-30</sup>和0非常近，也和负的1e<sup>-30</sup>非常近但是当单位是ULP的时，这是一个非常大的距离。_

处理了这个特殊情况之后我们只需要简单的减去整数部分，获取绝对值，然后我们知道了它们之间的差是多少。`ulpsDiff`值告诉我们两个浮点数之间有多少个浮点数（加一），这是一种非常直观的与浮点误差打交道的方式。

一个ULP很好（浮点数相邻）。

一百万个ULP很不好（应该不相等）。

用ULP比较数值只是众多相对比较方式中的一种。在极限时它有着完全不一样的特性，但是对于普通的数字来说它很好用。这个概念足够的普通所以boost库有计算两个数字之间ULP的函数。

一个ULP是两个数字之间最小的差。单精度浮点数ULP比双进度浮点数ULP大的多，但是这种命名方式既简洁又方便。我喜欢。
